Our method is built on top of coverage based fuzz testing and dynamic symbolic execution, where we have introduced distance based seed search strategy, symbolic loop bucket, and lazy symbolic pointer.
 While an improvement, there are still some drawbacks to our method. This section discusses these limitations and take a future look at the vulnerability discovery.
 
\subsection{Limitations}

\noindent\textit{\textbf{Distance Measurement:}} Our seed selection strategy leverages three well-known distance measures, i.e., Euclidean Distance, Cosine Similarity and Jaccard Index. Also, we have evaluated these three measures and compared the results with no search strategy. In the future, we hope to investigate other distance metrics (e.g.\ hamming distance, N-gram distance, etc.) to find a better measurement for different execution paths (or different seed inputs). 

\noindent\textit{\textbf{Plain Input Format:}} Programs that accept input with no specific format cannot gain performance improvement from our distance based seed selection method.
 As shown in Figure~\ref{path-detail}(a), all of these three distance based selection strategies failed to trigger more new behaviors for \texttt{capstone} which accepts the plain texture file as input. 

\noindent\textit{\textbf{Float Point Operation:}} The dynamic symbolic execution engine we depend on will concretize symbolic write operations to \texttt{XMM} registers, which will lose some interesting paths when handling float point arithmetic operations. This problem happens for most of the MEPG processing programs. So the dynamic symbolic execution engine should be upgraded to support float point arithmetic operations to handle these types of programs.

\subsection{Future Work on Vulnerability Detection}
This section will briefly propose some possible future research areas in vulnerability detection.

\subsubsection{Binary Transformations}
Considering the size and complexity of modern software, dynamic symbolic execution still faces the scalability problems. 
 Optimizations in compiler have deep affect to dynamic symbolic execution. 
 In 2013, J. Wagner et, al. proposed a new option \textsc{-Overify} which generates code optimized for the needs of verification tools.
  Their experiments' results show that \textsc{-Overify} can reduce verification time by up to 95x for GNU Coreutils \cite{wagner2013overify}.
 As discussed in \cite{Cadar:2015:TPT}, flag \texttt{-O0} of LLVM compiler can contribute different paths from flag \texttt{-O2} (which contributes 1024 and 2 paths respectively for its sample code).
 C. Cadar claims that one should treat program transformations as first-class ingredients of scalable symbolic execution, alongside widely-accepted aspects such as search heuristics and constraint solving optimizations \cite{Cadar:2015:TPT}. 
 
With such insights, we propose that, in the future, binary executables should be pre-processed to transform \textit{testing-expensive} code structures to \textit{testing-cheap} ones.
  Similar as what is implemented in \cite{wagner2015high}, the binary pre-processing stage should recognize which code areas are the testing ``hot spot'' and remove/transform them to avoiding getting stuck in such areas.
  These transformations can either be semantics-preserving transformations or semantic-altering transformations. 
 However, the key problem is how to perform such transformation on binary level since many program information have been lost during compiling. 
 On possible solution to achieve such transformations is to lift binary code into intermediate expression such as LLVM byte code. 

\subsubsection{Finding Bugs with Machine Learning}
Many research papers treat the vulnerability detection with dynamic symbolic execution and fuzz testing as a search problem.
 Since the search space of modern software can be vast,exhaustively exploration of the program's space is impossible.
 Reducing the search space can lead to better coverage in a reduced test scope.
 However, this may miss interesting sub-spaces where contain vulnerabilities. 
 In to find more deeper bugs when reducing the search space, one has to locate \textit{secure-sensitive code areas} based on static analysis, and then uses search heuristics to guide the program execute to these areas.
 Since each type of vulnerability has its unique characteristic \cite{MBishop:ATBOC, wang2009intscope, wang2010ricb}. 
 Some researchers have attempted to use machine learning to automatically extract such characteristics in source code, and then predict potential vulnerabilities \cite{VCCFinder, Yamaguchi:2011:VEA}.

In 2016, G. Grieco et, al. proposed a binary software vulnerability predict tool \textsc{VDiscover} as well as a public dataset that collects raw analyzed data \cite{Grieco:2016:TLV}. 
 And they managed to predict with reasonable accuracy which programs contained dangerous memory corruptions.
 So based on such work progress, we propose that, in the future, machine learning can be ported to binary software vulnerability detection by cooperating with guided testing method. Since machine learning may raise false positives, one can leverage guided dynamic symbolic execution to mitigate the false positives and verify the existence of potential vulnerabilities.