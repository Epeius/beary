As mentioned before, the size of the seed queue of coverage based evolutionary fuzz testing will quickly reach a large number (especially with the assistance of symbolic execution) when testing large-scale modern software. The seed queue should be rearranged to make sure we can find more paths when given the time budget.

We realized that different seed files in the queue have different power of finding new paths. For example in Figure~\ref{motivate-example}, suppose the state space of a program is modeled as a two-dimensional space, and each input that triggers new behavior will be mapped to a specific dot in the space. The fuzz test starts from an initial seed which is marked as red in this figure. The mutation results of this initial seed cover the black points as well as seed A and seed B. Then, in evolutionary fuzz testing, a test case will be picked up as the seed file for next round of mutation. 
Consider the choice between seed A and B in this figure, the \emph{distance}(eg. Euclidean Distance) from the initial seed file to A is much shorter than B, which, in other words, means that A is more \textbf{\textit{similar}} to the initial seed file than B. So choosing A as the next seed file to mutate will only trigger two new paths as most of the mutated test cases are (the blue area) overlapped by what the initial seed has mutated (the gray area). However, because seed B has a longer distance from the initial seed than seed A, the coverage area of B (the brown area) will have less overlap by that of initial seed file than A. So choosing seed B will trigger more new behaviors than selecting seed A.


Based on this insight, we proposed a test case prioritization method based on \emph{distance} between test cases. Our method investigated three distance measures, i.e., \textit{Euclidean Distance}, \textit{Cosine Similarity} and \textit{Jaccard Index}, as the classification metrics for test case prioritization. Each test case in the seed queue will be assigned with a \emph{weight} value after being mapped as a vector from input space to state space. The \emph{weight} value is utilized as the criteria to determine which seed file should be scheduled as the next seed through a global optimum solution.

In the following sections, we firstly introduce these three distance metrics and then explain how a test case is mapped to a numerical vector as well as the seed selection method.

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{figures/motivate-example.pdf} 
\caption{A motivating example.}\label{motivate-example}
\end{figure}

\subsection{Distance Metrics}
For two vectors $\mathit{X} = (x_1, x_2, \cdots, x_N)$ and $\mathit{Y} = (y_1, y_2, \cdots, y_N)$, the corresponding similarity metrics for \textit{Euclidean Distance}, \textit{Cosine Similarity} and \textit{Jaccard Index} are listed as follows.

\begin{enumerate}
\item Euclidean Distance (EU)

The Euclidean Distance between two vectors is defined as follows:
\begin{center}
$EU(\mathit{X}, \mathit{Y}) = \displaystyle \sqrt{\sum_{i=1}^{N} (x_i-y_i)^2}$
\end{center}


\item Cosine Similarity (CS)

The consine similarity between $\mathit{X}$ and $\mathit{Y}$ is defined as follows:

\begin{center}
$CS(\mathit{X}, \mathit{Y}) = \displaystyle \sqrt{\frac{\mathit{X}^T \cdot \mathit{Y}} {\| \mathit{X} \|\| \mathit{Y} \|}}$
\end{center}
where $\mathit{X}^T$ is a transposition of vector $\mathit{X}$ and $\| \mathit{X}\|$ is the Euclidean Distance of
vector $\mathit{X}$. Similarly, $\|\mathit{Y}\|$ is the Euclidean norm of vector $\mathit{Y}$. In essence, \textit{CS} is the cosine of the angle between $\mathit{X}$ and $\mathit{Y}$ in the N-dimensional space. For cosine similarly, the corresponding distance is defined as:

\begin{center}
$D(\mathit{X},\mathit{Y}) = 1 - CS(\mathit{X},\mathit{Y})$
\end{center}

\item Jaccard Index (JI)

The Jaccard Index between $\mathit{X}$ and $\mathit{Y}$ is defined as follows:

\begin{center}
$JI(\mathit{X}, \mathit{Y}) = \displaystyle \frac{\mathit{X} \cdot \mathit{Y}}{\mathit{X} \cdot \mathit{Y}+\omega(\|\mathit{X}\|^2+\|\mathit{Y}\|^2-2(\mathit{X} \cdot \mathit{Y}))}$
\end{center}

where $\mathit{X} \cdot \mathit{Y}$ is the inner product of $\mathit{X}$ and $\mathit{Y}$. 
When $\omega$ is equal to 1, the above formula is called Jaccard index and its corresponding distance is defined as follows:

\begin{center}
$D(\mathit{X},\mathit{Y}) = 1 - JI(\mathit{X},\mathit{Y})$
\end{center}

\end{enumerate}

\subsection{Seed Selection Method}
In order to measure the distances between test cases, all the test cases should be mapped as numerical vector. 
The mapping can be performed both from input space and state space. Mapping from input space cannot reflect the real relationship between test cases when considering the behavior of the target program. For example, as shown in Figure~\ref{distance-illusion}, multiple different inputs can steer the program to execute the same path. Specifically, considering the three test cases namely \texttt{A.jpeg}, \texttt{B.jpeg} and \texttt{C.jpeg} in this figure, suppose the corresponding contents are shown as follows:
\\
\\
\indent\texttt{A.jpeg}: \texttt{$\backslash$xFF$\backslash$xD8$\backslash$xAA$\backslash$xBB$\backslash$xCC$\backslash$xDD}

\texttt{B.jpeg}: \texttt{$\backslash$xFF$\backslash$xD8$\backslash$xDD$\backslash$xCC$\backslash$xBB$\backslash$xAA}

\texttt{C.jpeg}: \texttt{$\backslash$xFE$\backslash$xD8$\backslash$xAA$\backslash$xBB$\backslash$xCC$\backslash$xDD}
\\

\indent Obviously, if we calculate the \textit{Euclidean Distance} between these three files based from input space, $ED_{AB}$ will be greater than $ED_{AC}$ because there are more different bytes between \texttt{A.jpeg} and \texttt{B.jpeg} than that of \texttt{A.jpeg} and \texttt{C.jpeg}. This means \texttt{A.jpeg} and \texttt{C.jpeg} are more similar (as shown in Figure~\ref{distance-illusion}) from the viewpoint of input space. 
However, for most of JPEG process programs, \texttt{A.jpeg} and \texttt{B.jpeg} will execute the same path, and \texttt{C.jpeg} will execute another path because \texttt{C.jpeg} is an illegal JPEG file (bad magic number). So from the viewpoint of the program, \texttt{A.jpeg} and \texttt{B.jpeg} are more similar than \texttt{A.jpeg} and \texttt{C.jpeg} even though \texttt{A.jpeg} and \texttt{C.jpeg} have only one bit difference. 
Since our objective is to maximize the coverage in the state space, so we choose to map all the test cases from the state space to numeric vectors to calculate the distance.

In \cite{wang2015similarity} all test cases are represented as a branch coverage vector $\mathit{V}=(v_1, v_2, \cdots, v_N)$, where $v_i$ is 0 means the branch is covered, otherwise 1. 
However, different test cases can affect different number of branches, so the mapped vectors may have different lengths which cannot be used directly for distance calculation. Meanwhile, it will be difficult to construct such vectors because it is hard to obtain all the branches and list them orderly in each vector to avoid obfuscation between vectors. 
In AFL \cite{online:afl}, the execution path information of each test case is stored as a \emph{Bitmap}. By checking the hit count of this bitmap, AFL determines whether some new behaviors are triggered. So as this bitmap contains enough information to reflect the characteristics of a test case from the viewpoint of the state space, we choose the bitmap as our mapped vector to mitigate the costly mapping in \cite{wang2015similarity}.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{figures/distance-illusion.pdf} 
\caption{An illusion for distance.}\label{distance-illusion}
\end{figure}

Based on the mapped bitmap vectors, the test case queue in the fuzzer is enhanced by assigning each test case with weight $W$ which is obtained from the distance between every two test cases. Whenever a new seed file is found, the distance between this seed file and all the other files in the queue will be measured to calculate $W$. Meanwhile, the weight of all the other files in the queue will be updated according to the distance to the new seed file. 

Rather than selecting the seed file that has the longest distance to the current seed file which is only a \emph{local optimum solution}, our search method selects the file that takes the longest average distance from all the other test cases as the next seed file. By doing this, we can achieve a \emph{global optimum solution} for this searching problem. The weight $W$ for test case $t_k$ is defined as follows:

\begin{center}
$W_k = \displaystyle\frac{1}{N} \sum_{i=0}^{N} D(t_i, t_k)$
\end{center}
where $D(t_i, t_k)$ denotes the distance between $t_i$ and $t_k$ based on the three distance measures mentioned before, and $N$ is the size of the test case queue. 

We also noticed that even two test cases have the same $W$ value, they may have different power on finding new paths.
 This is because path coverage is not the only criteria for testing, and other runtime information, such as memory operations, can also be leveraged to prioritize test cases. 
 So we enhanced the weigh $W$ with memory coverage to achieve better prioritization result. The enhanced weight $\hat{W_k}$ for test case $t_k$ is defined as the following formula, where $M(t_k)$ denotes the number of memory cells that $t_k$ covers in byte.
\begin{center}
$\hat{W_k} = \displaystyle M(t_k) + \frac{1}{N} \sum_{i=0}^{N} D(t_i, t_k)$
\end{center} 