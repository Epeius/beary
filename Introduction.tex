

Fuzz testing is a popular technique for automatic software
vulnerability detection \cite{Miller:Fuzz, 5010257, sutton2007fuzzing}.
However, it suffers from low efficiency when applied to real-world
software \cite{neystadt2008automated, godefroid2008automating,
ganesh2009taint, cadar2011symbolic, rawat2017vuzzer,
stephens2016driller}, which often has complex input formats, e.g.,
Portable Document Format (PDF). Most of the test cases generated by
fuzz testing will be discarded on the shallow surface of such software.
In order to improve the performance of traditional fuzz testing,
coverage-based fuzz testing collects all of the test cases that
contribute to the coverage into a seed file queue. The fuzzer then
generates new test input from the seed queue using genetic methods
\cite{rawat2017vuzzer, online:afl, stephens2016driller}. Although
coverage-based fuzz testing is able to discover more paths than
traditional fuzz testing, it is nevertheless incapable of triggering
bugs that are deeply nested in complex code areas (due to the usage of
random mutation).

Recently, dynamic symbolic execution has been employed to improve the
efficiency of fuzz testing as a form of hybrid testing
\cite{godefroid2012sage, yeh2015craxfuzz, majumdar2007hybrid,
pak2012hybrid}. In this approach, corner cases that are difficult for
fuzzers to cover are generated from dynamic symbolic execution by
solving the corresponding path conditions. Meanwhile, dynamic symbolic
execution can also benefit from the seed files in the fuzzer's seed
queue to quickly reach more wider code areas. Driller, which is built
on top of the Angr symbolic execution engine
\cite{Shoshitaishvili_firmalice-automatic} and AFL fuzzing engine
\cite{online:afl}, has attempted to leverage symbolic execution to
solve the branches guarded by complex path conditions to avoid
saturation of fuzzer \cite{stephens2016driller}. Driller's performance
in DARPA's Cyber Grand Challenge (CGC) \cite{online:CGC} demonstrates
the potential of these hybrid testing approaches.


In hybrid testing, such as Driller, the performance gain from dynamic
symbolic execution is still limited by particular program
structures(e.g., symbolic pointers and loops) \cite{schwartz2010all,
Boonstoppel:RAP, cadar2011symbolic, baldoni2016survey}. Such structures
will quickly generate many states that may not trigger new behaviors
but result in \textit{state explosion}. Moreover, by leveraging dynamic
symbolic execution, the seed queue of the fuzzer will quickly reach a
large number for modern software.
%So when given the testing time budget, the seed queue should be rearranged to make sure
%that test case with greater probability of triggering new paths will be scheduled with high priority.

In this paper, we propose two advanced techniques to improve the
efficiency of dynamic symbolic execution assisted hybrid testing.  On
one hand, based on the lazy forking technique employed in
S2E\cite{chipounov2011s2e}, we concretize symbolic pointers to avoid
generating too many states but solve the pending states that are
forked from these pointers on demand to cover more branches. An
optimization based on AFL's \cite{online:afl} loop bucket mechanism is
also introduced to avoid getting stuck in symbolic loops. On the other
hand, to address the large size of seed queue, we propose a distance
based seed selection method for fuzz testing to improve the coverage
when testing time is limited. Each seed in the queue is equipped with
an weight value, obtained from the execution runtime information,
which includes both path coverage and memory coverage. Our method
prioritizes the seed queue according to this weight value and then
selects the seed file with the greatest weight value for next mutation
cycle.


Our main contributions consist of two main components, namely
\emph{Symbolic Path Finder (SPF)} and \emph{Seacher}. The \emph{SPF}
component is leveraged to help the fuzzer dive into deeper code areas
that are guarded by complex path constraints. Techniques to handle the
\textit{state explosion} problem raised by symbolic pointers and loops
are implemented inside of \emph{SPF}. The \emph{Searcher} is designed
to select the most promising seed file from the seed queue based on the
distance measurement. By doing this, the fuzzer will reach previously
untouched code areas as soon as possible in a given time budget.  Last
but not least,  we have implemented the proposed techniques in a
prototype tool, and performed comprehensive experimental evaluations on
three different benchmarks. The benchmarks consist of: a demo program
which contains 9 different types of bugs; the LAVA benchmark suite
\cite{dolan2016lava}; and a set of real world UNIX programs. The
results show that our prototype can trigger more bugs than other
state-of-the-art vulnerability detection tools. We also evaluated the
path discovery ability of our prototype on a benchmark which contains
several real-world UNIX programs, and the result shows that our
approach can discover 43.49\% more unique paths in average than vanilla
fuzz testing.

In summary, this paper makes the following contributions:
\begin{itemize}

\item We introduce a technique to avoid forking more
states by postponing the concretization of symbolic pointer to the
moment when branch condition depends on such pointer.

\item We also
present an optimization namely \emph{symbolic loop bucket} to ease the
\textit{state explosion} problem by limiting the looping times into a
serial of fixed buckets.

\item A \emph{distance based seed selection}
method is proposed to select the most promising seed in the queue
according to the runtime information to improve path coverage.
\end{itemize}


The rest of this paper is organized as follows.
Section~\ref{sec:preliminaries} describes the basic conception of
dynamic symbolic execution and hybrid testing. Section~\ref{sec:ease
PE} presents the details of how we deal with \textit{state explosion}
raised from symbolic pointers and loops. The distance based seed
selection method is discussed in Section~\ref{sec:seed selection}.
Section~\ref{sec:evaluate} describes the implementation of our
prototype and the evaluation results. Section~\ref{sec:discussion}
discusses the limitations of our work and possible counter measures.
Section~\ref{sec:related} reviews the related work, and
Section~\ref{sec:conclusion} concludes this paper.
