Fuzz testing is the most popular automatic method to discover vulnerabilities in software. Many security vulnerabilities are found by fuzz testing every year. However, traditional fuzz testing can only discover bugs that exist on the shallow surface of programs. This is because that the fuzzers treat the target software as black box and feeds them with randomly generated input data. While the complex input formats in modern software determine that only a very small portion of the randomly generated test cases can trigger new behaviors of the target binary by touching new paths. So low efficiency is still the main bottleneck of fuzz testing when applying to real-world modern software. 

Coverage based fuzz testing collects all the test cases that trigger new behaviors into a seed file queue. All the test cases in this queue will be picked up as the template file for a new mutation generation. By utilizing such genetic method, the fuzzer can quickly touch more new paths and find more bugs than traditional fuzz testing. Even though this genetic method can cover more paths, the test case generation strategy (i.e randomly mutation) still cannot trigger the bugs that deeply nested in complex code areas.  


Some hybrid testing methods try to improve the efficiency of coverage based fuzz testing by employing the advantages of other program testing/analysis methods (i.e. symbolic execution and static analysis). 
Leveraging symbolic execution has been proved to be a promising approach to improve the testing performance. Because symbolic execution can easily cover some \textit{corner cases} which is difficult for fuzzer to cover. Meanwhile, symbolic execution can also benefit from the seed files in the queue from fuzzer to quickly reach more \textit{wider} code areas. Driller, which is built on top of Angr symbolic execution engine and AFL fuzzing engine, has attempted to leverage symbolic execution to assist fuzz testing in exploring as many as paths \cite{stephens2016driller}. And its performance in the CGC challenge \cite{online:CGC} has been the great support for this hybrid testing approach.

Even through the symbolic execution in hybrid testing can improve the efficiency of fuzz testing, the performance gain is still deeply affected by some program structures/instructions (like loops and symbolic pointers). Such structures will quickly generate lots of states that cannot trigger new behaviors but raise the intrinsic \textit{path explosion} problem of symbolic execution. 

Meanwhile, by leveraging symbolic execution, the seed queue of the fuzzer will quickly reach a large number for modern software. Mutation and symbolic execution on every seed file in the queue will last for a long time which may expire the budget testing time. So when given the testing time budget, the seed queue should be rearranged to make sure the test case that has greater probability to trigger new paths will be tested with high priority. 

In this paper, we introduced two improvements to ease the \textit{path explosion} problem raised from the symbolic loops and symbolic pointers when using symbolic execution to assist coverage based fuzz testing. To address the large size of seed queue, we proposed a distance based seed privatization strategy for fuzz testing to speed up the path discovery by selecting the most promising seed file to mutate. 
And we also designed and implemented the prototype which is built on top of our method. Furthermore, some additional evaluations on different benchmarks are performed to demonstrate the ability of our methods.

In summary, this paper makes the following contributions.
\begin{itemize}
\item A \emph{symbolic loop bucket} method and a novel \emph{lazy symbolic pointer} method based on lazy forking are presented to ease the \emph{path explosion} problem when using symbolic execution to assist fuzz testing.

\item A \emph{distance based seed privatization} method is proposed to improve the path discovery when testing time is limited.
\end{itemize}

In the rest of the paper, we present the details of our methodology (Section~\ref{sec:methodology}), give the implementation of our prototype (Section~\ref{sec:imple}), evaluate it (Section~\ref{sec:evaluate}), discuss the limitations (Section~\ref{sec:discussion}), survey the related work (Section~\ref{sec:related}), and conclude our work (Section~\ref{sec:conclusion}).
